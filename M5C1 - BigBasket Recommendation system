# Importing libraries
library(data.table)           
library(readxl)               
library(tidyverse)
library(lubridate)
library(skimr)                
library(knitr)                
library(treemap)

#Loading and Inspecting the Data----

# import raw data file and trim leading and trailing whitespaces
setwd("C:\\Users\\gyana\\OneDrive\\Documents\\R\\WB\\AIPM\\mod5\\Case1")
retail <- read_excel("01_Customer_Analytics_at_Bigbasket_-_Product_Recommendations.xls", trim_ws = TRUE)

# First glance at the data
retail %>%  skim()

'-- Variable type: character --------------------------------------------------------
  # A tibble: 3 x 8
  skim_variable n_missing complete_rate   min   max empty n_unique whitespace
* <chr>             <int>         <dbl> <int> <int> <int>    <int>      <int>
1 Member                0             1     6     6     0      106          0
2 Created On            0             1     5    18     0     8352          0
3 Description           0             1     3   169     0      216          0'

'-- Variable type: numeric----------------------------------------------------
  # A tibble: 2 x 11
  skim_variable n_missing complete_rate      mean        sd      p0      p25
* <chr>             <int>         <dbl>     <dbl>     <dbl>   <dbl>    <dbl>
1 Order                 0             1  7642313.   513112. 6422558  7457967
2 SKU                   0             1 17743228. 14424766. 6884195 15668381'

#Checking if there is any Na is the dataset.
sum(is.na(retail)) # no missing values found in the data

# I need to arrange the data by order no - item format
sapply(retail[,c('Order','Member')], function(x) length(unique(x)))

# 106 members have ordered 8387 total in numbers.

retail <- retail %>%
  # Setting 'Description' as factors
  mutate(Description = as.factor(Description)) %>%
  # Changing 'Order' type to numeric
  mutate(Order = as.numeric(Order))%>% 
  # Extracting 'Date' and 'Time' from 'InvoiceDate'
  mutate(Date = as.Date(retail$Created_On))%>% print() 
  #mutate(Time = as.factor(format(retail$Created_On,"%H:%M:%S")))


glimpse(retail)

#Exploratory Data Analysis

#What items do people buy more often?

retail %>% 
  group_by(Description) %>% 
  summarize(count = n()) %>% 
  top_n(10, wt = count) %>%
  arrange(desc(count)) %>% 
  ggplot(aes(x = reorder(Description, count), y = count))+
  geom_bar(stat = "identity", fill = "royalblue", colour = "blue") +
  labs(x = "", y = "Top 10 Best Sellers") +
  coord_flip() +
  theme_grey(base_size = 12)


#Top 10 items sold

retail %>% 
  group_by(Description) %>% 
  summarize(count = n()) %>% 
  mutate(pct=(count/sum(count))*100) %>% 
  arrange(desc(pct)) %>% 
  ungroup() %>% 
  top_n(10, wt=pct)

'Description        count pct
<fct>               <int> <dbl>
1 Other Vegetables  4606  7.41
2 Beans             4549  7.32
3 Root Vegetables   4303  6.92
4 Other Dals        3272  5.27
5 Organic F&V       3113  5.01
6 Whole Spices      3001  4.83
7 Gourd & Cucumber  2973  4.78
8 Brinjals          2569  4.13
9 Namkeen           2224  3.58
10 Banana           2188  3.52'

#What time of day do people buy more often?

#retail %>% 
 # ggplot(aes(hour(hm(Time)))) + 
  #geom_histogram(stat = "count",fill = "#E69F00", colour = "red") +
  #labs(x = "Hour of Day", y = "") +
  #theme_grey(base_size = 12)

#What day of the week do people buy more often?
retail %>% 
  ggplot(aes(wday(Date, 
                  week_start = getOption("lubridate.week.start", 1)))) + 
  geom_histogram(stat = "count" , fill = "forest green", colour = "dark green") +
  labs(x = "Day of Week", y = "") +
  scale_x_continuous(breaks = c(1,2,3,4,5,6,7),
                     labels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")) +
  theme_grey(base_size = 14)

#How many items does each customer buy?
#retail %>% 
 # group_by(Order) %>% 
  #summarise(n = mean(Order)) %>%
  #ggplot(aes(x=n)) +
  #geom_histogram(bins = 100000, fill = "purple", colour = "black") + 
  #coord_cartesian(xlim=c(0,100)) +
  #scale_x_continuous(breaks=seq(0,100,10)) +
  #labs(x = "Average Number of Items per Purchase", y = "") +
  #theme_grey(base_size = 14)

# Importing libraries
library(data.table)
library(tidyverse)            
library(knitr)
library(recommenderlab)


retail <- retail %>% 
  # create unique identifier
  mutate(InNo_Desc = paste(Order, Description, sep = ' ')) 
# filter out duplicates and drop unique identifier
retail <- retail[!duplicated(retail$InNo_Desc), ] %>% 
  select(-InNo_Desc)

# CHECK:  total row count - 517,354

ratings_matrix <- retail %>%
  # Select only needed variables
  select(Order, Description) %>% 
  # Add a column of 1s
  mutate(value = 1) %>%
  # Spread into user-item format
  spread(Description, value, fill = 0) %>%
  select(-Order) %>%
  # Convert to matrix
  as.matrix() %>%
  # Convert to recommenderlab class 'binaryRatingsMatrix'
  as("binaryRatingMatrix")

ratings_matrix
#8387 x 216 rating matrix of class 'binaryRatingMatrix' with 50158 ratings.

"In order to establish the models effectiveness, recommenderlab implements a number of evaluation schemes. In this scheme, I split the data into a train set and a test set by selecting train = 0.8 for a 80/20 train/test split. I have also set method = cross and k = 5 for a 5-fold cross validation. This means that the data is divided into k subsets of equal size, with 80% of the data used for training and the remaining 20% used for evaluation. The models are recursively estimated 5 times, each time using a different train/test split, which ensures that all users and items are considered for both training and testing. The results can then be averaged to produce a single evaluation.

Selecting given = -1 means that for the test users 'all but 1' randomly selected item is withheld for evaluation."

scheme <- ratings_matrix %>% 
  evaluationScheme(method = "cross",
                   k      = 5, 
                   train  = 0.8,  
                   given  = -1)

#Set up List of Algorithms

"One of recommenderlab main features is the ability to estimate multiple algorithms in one go. First, I create a list with the algorithms I want to estimate, specifying all the models parameters. Here, I consider schemes which evaluate on a binary rating matrix and include the random items algorithm for benchmarking purposes."

algorithms <- list(
  "association rules" = list(name  = "AR", param = list(supp = 0.01, conf = 0.01)),
  "random items"      = list(name  = "RANDOM",  param = NULL),
  "popular items"     = list(name  = "POPULAR", param = NULL),
  "item-based CF"     = list(name  = "IBCF", param = list(k = 5)),
  "user-based CF"     = list(name  = "UBCF", param = list(method = "Cosine", nn = 500))
)

#Estimate the Models
"All I have to do now is to pass scheme and algoritms to the evaluate() function, select type = topNList to evaluate a Top N List of product recommendations and specify how many recommendations to calculate with the parameter n = c(1, 3, 5, 10, 15, 20).

Please note that the CF based algorithms take a few minutes each to estimate."

results <- recommenderlab::evaluate(scheme, 
                                    algorithms, 
                                    type  = "topNList", 
                                    n     = c(1, 3, 5, 10, 15, 20))

results

#Inspecting the result

results$'popular' %>% 
  getConfusionMatrix() 

#Visulizing result
"I arrange the confusion matrix output for one model in a convenient format."

# Pull into a list all confusion matrix information for one model 
tmp <- results$`user-based CF` %>%
  getConfusionMatrix()  %>%  
  as.list() 
# Calculate average value of 5 cross-validation rounds 
as.data.frame( Reduce("+",tmp) / length(tmp)) %>% 
  # Add a column to mark the number of recommendations calculated
  mutate(n = c(1, 3, 5, 10, 15, 20)) %>%
  # Select only columns needed and sorting out order 
  select('n', 'precision', 'recall', 'TPR', 'FPR') 

#Now, I put the previous steps into a formula.

avg_conf_matr <- function(results) {
  tmp <- results %>%
    getConfusionMatrix()  %>%  
    as.list() 
  as.data.frame( Reduce("+",tmp) / length(tmp)) %>% 
    mutate(n = c(1, 3, 5, 10, 15, 20)) %>%
    select('n', 'precision', 'recall', 'TPR', 'FPR') 
}

#Next, I use the map() function from the purrr package to get all results in a tidy format, ready for charting.

# Using map() to iterate function across all models
results_tbl <- results %>%
  map(avg_conf_matr) %>% 
  # Turning into an unnested tibble
  enframe() %>%
  # Unnesting to have all variables on same level
  unnest()

results_tbl


#ROC

"Classification models performance can be compared using the ROC curve, which plots the true positive rate (TPR) against the false positive rate (FPR).

The popular items, association rules and  item-based collaborative filtering model is the clear winner as it achieves the highest TPR for any given level of FPR. This means that the model is producing the highest number of relevant recommendations (true positives) for the same level of non-relevant recommendations (false positives).

Note that using fct_reorder2() arranges plot legend entries by best final FPR and TPR, aligning them with the curves and making the plot easier to read."
results_tbl %>%
  ggplot(aes(FPR, TPR, colour = fct_reorder2(as.factor(name), FPR, TPR))) +
  geom_line() +
  geom_label(aes(label = n))  +
  labs(title = "ROC curves",
       colour = "Model") +
  theme_grey(base_size = 14)

#Precision-Recall curve

"Another common way to compare the performance of classification models is with Precision Vs Recall curves. Precision shows how sensitive models are to False Positives (i.e. recommending an item not very likely to be purchased) whereas Recall (which is just another name for the TPR) looks at how sensitive models are to False Negatives (i.e. do not suggest an item which is highly likely to be purchased).

Normally, we care about accurately predicting which items are more likely to be purchased because this would have a positive impact on sales and revenue. In other words, we want to maximise Recall (or minimise FNs) for the same Precision.

The plot confirms that popular items, association rules and item-based CF are the best model because it has higher Recall (i.e. lower FNs) for any given level of Precision. This means that IBCF minimises FNs (i.e. not suggesting an item highly likely to be purchased) for all level of FPs."

results_tbl %>%
  ggplot(aes(recall, precision, 
             colour = fct_reorder2(as.factor(name),  precision, recall))) +
  geom_line() +
  geom_label(aes(label = n))  +
  labs(title = "Precision-Recall curves",
       colour = "Model") +
  theme_grey(base_size = 14)

#Predictions for a new user

"The final step is to generate a prediction with the best performing model. To do that, I need to create a made-up purchase order.

First, I create a string containing 6 products selected at random."

customer_order <- c("Other Rice Products","Cakes","Chips",
                    "Banana","Cashews","Moong Dal")

#Next, I put this order in a format that recommenderlab accepts.

new_order_rat_matrx <- retail %>% 
  # Select item descriptions from retail dataset
  select(Description) %>% 
  unique() %>% 
  # Add a 'value' column with 1's for customer order items
  mutate(value = as.numeric(Description %in% customer_order)) %>% 
  # Spread into sparse matrix format
  spread(key = Description, value = value) %>% 
  # Change to a matrix
  as.matrix() %>% 
  # Convert to recommenderlab class 'binaryRatingsMatrix'
  as("binaryRatingMatrix")

#Now, I can create a Recommender. I use getData to retrieve training data and set method = "IBCF" to select the best performing model ("item-based collaborative filtering").

recomm_IBCF <- Recommender(getData(scheme, 'train'), 
                      method = "IBCF",  
                      param = list(k = 5))

recomm_IBCF

#Finally, I can pass the Recommender and the made-up order to the predict function to create a top 10 recommendation list for the new customer.

pred <- predict(recomm_IBCF, 
                newdata = new_order_rat_matrx, 
                n       = 10)
as(pred, 'list')

# predicting popular items

recomm_popular <- Recommender(getData(scheme, 'train'), 
                           method = "POPULAR",  
                           param = list(k = 5))

recomm_popular

#Finally, I can pass the Recommender and the made-up order to the predict function to create a top 10 recommendation list for the new customer.

pred <- predict(recomm_popular, 
                newdata = new_order_rat_matrx, 
                n       = 10)
as(pred, 'list')


# predicting UBCF

recomm_UBCF <- Recommender(getData(scheme, 'train'), 
                              method = "UBCF",  
                              param = list(k = 5))

recomm_UBCF

#Finally, I can pass the Recommender and the made-up order to the predict function to create a top 10 recommendation list for the new customer.

pred <- predict(recomm_UBCF, 
                newdata = new_order_rat_matrx, 
                n       = 10)
as(pred, 'list')



#App Deployment
"For the app deployment I need to create 2 data files: past_orders_matrix and item_list.

past_orders_matrix is a user-item sparse matrix containing the history of past orders. This is needed in the Shiny server.R file for all the calculations."

past_orders_matrix <- retail %>%
  # Select only needed variables
  select(Order, Description) %>% 
  # Add a column of 1s
  mutate(value = 1) %>%
  # Spread into user-item format
  spread(Description, value, fill = 0) %>%
  select(-Order) %>% 
  # Convert to matrix
  as.matrix() %>% 
  # Convert to class "dgCMatrix"
  as("dgCMatrix")

saveRDS(past_orders_matrix, 
        file = "C:\\Users\\gyana\\OneDrive\\Documents\\R\\WB\\AIPM\\mod5\\Case1\\past_orders_matrix.rds")

# Creating a unique items list
item_list <- retail %>% 
  select(Description) %>% 
  unique()

#I save the list for use in the app.

saveRDS(item_list, 
        file = "C:\\Users\\gyana\\OneDrive\\Documents\\R\\WB\\AIPM\\mod5\\Case1\\item_list.rds")

#Creating a dummy order
customer_order <- c("Other Rice Products","Cakes","Chips",
                    "Banana","Cashews","Moong Dal")

#Next, I to put new_order in a user_item matrix format.
# put in a matrix format
new_order <- item_list %>%
  # Add a 'value' column with 1's for customer order items
  mutate(value = as.numeric(Description %in% customer_order)) %>%
  # Spread into sparse matrix format
  spread(key = Description, value = value) %>%
  # Change to a matrix
  as.matrix() %>% 
  # Convert to class "dgCMatrix"
  as("dgCMatrix")

#Then, I add the new_order to the past_orders_matrix as its first entry.

# binding 2 matrices
all_orders_dgc <- t(rbind(new_order,past_orders_matrix))

#Now, I need to set a number of parameters required by the Improved CF to work.

# Set range of items to calculate predictions for - here I select them all
items_to_predict <- 1:nrow(all_orders_dgc)
# Set current user to 1, which corresponds to new_order
users <- c(1)
# Set prediction indices
prediction_indices <- as.matrix(expand.grid(items_to_predict, users = users))

#I load the algorithm implementations and similarity calculations.

library(tidyverse)            
library(knitr)
library(Matrix)
library(recommenderlab)
# Load algorithm implementations and similarity calculations
source("C:\\Users\\gyana\\OneDrive\\Documents\\R\\WB\\AIPM\\mod5\\Case1\\cf_algorithm.R")
source("C:\\Users\\gyana\\OneDrive\\Documents\\R\\WB\\AIPM\\mod5\\Case1\\similarity_measures.R")

start <- Sys.time()
recomm <- predict_cf(all_orders_dgc, prediction_indices,
                     "ibcf", FALSE, cal_cos, 3, FALSE, 4000, 2000)
end <- Sys.time()
cat('runtime', end - start)

#Let's now run the item-based CF model with recommenderlab and compare performances.

# Convert `all_orders` to class "binaryRatingMatrix"
all_orders_brm <- as(all_orders_brm, "binaryRatingMatrix")

# Run run IBCF model on recommenderlab
start <- Sys.time()
recomm <- Recommender(all_orders_brm, 
                      method = "IBCF",  
                      param = list(k = 5))
end <- Sys.time()
cat('runtime', end - start)
